{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b6ba800-63fe-4d00-a1e7-68d6a4c72e60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Try Augmenting the Data to Boost the Signal**\n",
    "\n",
    "Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97044d96-1579-42e1-85e8-0f394d018eac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Inspect dataframe\n",
    "df = pd.read_csv(\"/dbfs/mnt/lab/unrestricted/rachel.lennon@defra.gov.uk/cleaned/all_balanced.csv\")\n",
    "\n",
    "# Parse df into numpy arrays\n",
    "def parse_signal(x):\n",
    "    \"\"\"Convert string or array-like signal to numeric numpy array\"\"\"\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return np.array(x, dtype=np.float32)\n",
    "    x = x.strip().replace(\"\\n\", \" \").replace(\",\", \" \")\n",
    "    x = x.strip(\"[]\")\n",
    "    return np.array(x.split(), dtype=np.float32)\n",
    "\n",
    "# Parse all signals\n",
    "signals = df[\"signal_scaled\"].apply(parse_signal)\n",
    "\n",
    "# Pad/truncate signals\n",
    "max_len = 1000  #10s at 100Hz\n",
    "X = pad_sequences(signals, maxlen=max_len, dtype=\"float32\",\n",
    "                  padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Labels\n",
    "y = df[\"fish_present\"].astype(np.float32).to_numpy()\n",
    "\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "545caa2a-112e-4fca-a651-9caa1c88ced1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b629689-0f5c-4361-bbbd-b21bebe165c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Augmentation functions\n",
    "def jitter(x, sigma=0.01):\n",
    "    return x + np.random.normal(0, sigma, size=x.shape)\n",
    "\n",
    "def scaling(x, sigma=0.1):\n",
    "    factor = np.random.normal(1.0, sigma)\n",
    "    return x * factor\n",
    "\n",
    "def time_shift(x, shift_max=50):\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    if shift > 0:\n",
    "        return np.concatenate([np.zeros(shift), x[:-shift]])\n",
    "    elif shift < 0:\n",
    "        return np.concatenate([x[-shift:], np.zeros(-shift)])\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def augment_positive_samples(X_pos, N_aug=5):\n",
    "    aug_list = []\n",
    "    for x in X_pos:\n",
    "        for _ in range(N_aug):\n",
    "            y = x.copy()\n",
    "            if np.random.rand() < 0.5: y = jitter(y, 0.02)\n",
    "            if np.random.rand() < 0.5: y = scaling(y, 0.1)\n",
    "            if np.random.rand() < 0.5: y = time_shift(y, shift_max=50)\n",
    "            aug_list.append(y)\n",
    "    return np.array(aug_list, dtype=np.float32)\n",
    "\n",
    "# Augment positives\n",
    "X_train_pos = X_train[y_train==1]\n",
    "X_train_neg = X_train[y_train==0]\n",
    "\n",
    "N_aug = 5\n",
    "X_aug = augment_positive_samples(X_train_pos, N_aug)\n",
    "y_aug = np.ones(len(X_aug))\n",
    "\n",
    "# Ensure 2D for concatenation\n",
    "X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "X_aug_2d = X_aug.reshape(X_aug.shape[0], -1)\n",
    "\n",
    "# Concatenate and shuffle\n",
    "X_train_aug = np.concatenate([X_train_2d, X_aug_2d], axis=0)\n",
    "y_train_aug = np.concatenate([y_train, y_aug], axis=0)\n",
    "X_train_aug, y_train_aug = shuffle(X_train_aug, y_train_aug, random_state=42)\n",
    "\n",
    "# Add channel dimension for Conv1D\n",
    "X_train_aug = X_train_aug[..., np.newaxis]\n",
    "X_val_exp = X_val[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0dc43d58-4681-42e7-bd01-85a38e89d8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7563f20e-530a-442f-a37d-e75a1732275b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "def simple_cnn(input_length):\n",
    "    inputs = layers.Input(shape=(input_length, 1))\n",
    "    x = layers.Conv1D(32, 5, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "model = simple_cnn(X_train_aug.shape[1])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62118430-cb0e-4062-b7d5-26aed377a790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2fce589-b61d-4e2e-8ceb-13bcc167d3a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# early stops\n",
    "early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    validation_data=(X_val_exp, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db4d3646-7b16-44aa-a78b-9cd82bec6da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf17f779-1092-4a29-bee8-74163da4ee11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Evaluate\n",
    "results = model.evaluate(X_val_exp, y_val, verbose=0)\n",
    "print(dict(zip(model.metrics_names, results)))\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = model.predict(X_val_exp)\n",
    "fpr, tpr, thr = roc_curve(y_val, y_pred_proba)\n",
    "threshold = thr[np.argmax(tpr - fpr)]\n",
    "\n",
    "y_pred = (y_pred_proba > threshold).astype(int).flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab46291c-7021-43a8-902f-3ca0b9ba4ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training and validation loss curves\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss, label=\"Training Loss\", color=\"tab:blue\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\", color=\"tab:orange\")\n",
    "\n",
    "# Mark the last points\n",
    "plt.scatter(len(train_loss)-1, train_loss[-1], color=\"tab:blue\", s=60, zorder=3)\n",
    "plt.scatter(len(val_loss)-1, val_loss[-1], color=\"tab:orange\", s=60, zorder=3)\n",
    "\n",
    "# Add offset labels with arrows for clarity\n",
    "plt.annotate(f\"{train_loss[-1]:.4f}\",\n",
    "             xy=(len(train_loss)-1, train_loss[-1]),\n",
    "             xytext=(10, 10), textcoords=\"offset points\",\n",
    "             ha=\"left\", color=\"tab:blue\",\n",
    "             arrowprops=dict(arrowstyle=\"->\", color=\"tab:blue\"))\n",
    "\n",
    "plt.annotate(f\"{val_loss[-1]:.4f}\",\n",
    "             xy=(len(val_loss)-1, val_loss[-1]),\n",
    "             xytext=(10, -15), textcoords=\"offset points\",\n",
    "             ha=\"left\", color=\"tab:orange\",\n",
    "             arrowprops=dict(arrowstyle=\"->\", color=\"tab:orange\"))\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7436f49a-e744-4746-8a4e-ad52a4767dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d8459b-2028-45d6-8eb4-506052133fce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"No Fish\", \"Fish\"],\n",
    "            yticklabels=[\"No Fish\", \"Fish\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.3_Augmenation_CNN",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
