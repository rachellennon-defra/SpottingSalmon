{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afa089c8-0c0a-4bed-8968-b23d8c297929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**UNet Resistivity Trial**\n",
    "\n",
    "Run the cleaned dataset through a UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "097eb84b-3af7-49a5-8a23-d9f00a35de0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Inspect dataframe\n",
    "df = pd.read_csv(\"/dbfs/FileStore/rachlenn/df_chunks.csv\")\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3624e00f-f7f8-400b-8d3a-169a0cab627d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_signal(x):\n",
    "    # If already list/array, just convert\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return np.array(x, dtype=np.float32)\n",
    "    # Otherwise assume it's a string like \"[ -1.63 -1.53 ... ]\"\n",
    "    x = x.strip().replace(\"\\n\", \" \")       # remove newlines\n",
    "    x = x.strip(\"[]\")                      # remove leading/trailing brackets\n",
    "    return np.array(x.split(), dtype=np.float32)\n",
    "\n",
    "signals = df[\"signal_scaled\"].apply(parse_signal)\n",
    "\n",
    "# Stack into 2D numpy array\n",
    "X = np.stack(signals.to_numpy())\n",
    "y = df[\"fish_present\"].astype(np.float32).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f30d3e6d-a282-4d02-9d40-563fbf47ea0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y\n",
    ")\n",
    "\n",
    "max_len = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d6c6c21-998b-40cb-a265-9026f6f8a3da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define 1D U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99e9bbf8-91f1-47ab-9f2a-da4f4d22297e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_1d(input_length, num_classes=1):\n",
    "    inputs = layers.Input(shape=(input_length, 1))\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv1D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv1D(16, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling1D(2)(c1)\n",
    "\n",
    "    c2 = layers.Conv1D(32, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv1D(32, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling1D(2)(c2)\n",
    "\n",
    "    c3 = layers.Conv1D(64, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv1D(64, 3, activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling1D(2)(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = layers.Conv1D(128, 3, activation='relu', padding='same')(p3)\n",
    "    b = layers.Conv1D(128, 3, activation='relu', padding='same')(b)\n",
    "\n",
    "    # Decoder\n",
    "    u3 = layers.UpSampling1D(2)(b)\n",
    "    u3 = layers.Concatenate()([u3, c3])\n",
    "    c6 = layers.Conv1D(64, 3, activation='relu', padding='same')(u3)\n",
    "\n",
    "    u2 = layers.UpSampling1D(2)(c6)\n",
    "    u2 = layers.Concatenate()([u2, c2])\n",
    "    c7 = layers.Conv1D(32, 3, activation='relu', padding='same')(u2)\n",
    "\n",
    "    u1 = layers.UpSampling1D(2)(c7)\n",
    "    u1 = layers.Concatenate()([u1, c1])\n",
    "    c8 = layers.Conv1D(16, 3, activation='relu', padding='same')(u1)\n",
    "\n",
    "    # Output (binary classification at sequence level)\n",
    "    gap = layers.GlobalAveragePooling1D()(c8)\n",
    "    output = layers.Dense(num_classes, activation='sigmoid')(gap)\n",
    "\n",
    "    model = models.Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "model = unet_1d(max_len)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC()])\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_1D-UNetTrial",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
