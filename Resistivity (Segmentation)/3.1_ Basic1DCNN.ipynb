{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a3466f9-5ab8-4356-bf30-c0f1181c9e25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Basic 1D CNN Model for small sample size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d88f9b10-509e-46a0-a3c6-e38e638ff2f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Inspect the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03a799d1-75e9-4881-a1f3-9ae7ace8a3f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Inspect dataframe\n",
    "df = pd.read_csv(\"/dbfs/mnt/lab/unrestricted/rachel.lennon@defra.gov.uk/cleaned/all_balanced.csv\")\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cf80059-f591-45de-a82f-79a653d06767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a63fe8-b1cd-4aab-8cfa-9d8630968050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Parse signal column into numeric arrays\n",
    "def parse_signal(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return np.array(x, dtype=np.float32)\n",
    "    # Otherwise assume string like \"[ -1.63 -1.53 ... ]\"\n",
    "    x = x.strip().replace(\"\\n\", \" \").replace(\",\", \" \")  # remove commas and newlines\n",
    "    x = x.strip(\"[]\")\n",
    "    return np.array(x.split(), dtype=np.float32)\n",
    "\n",
    "signals = df[\"signal_scaled\"].apply(parse_signal)\n",
    "\n",
    "# Pad/truncate all signals to fixed length (e.g., 10s * 100Hz = 1000)\n",
    "max_len = 1000\n",
    "X = pad_sequences(signals, maxlen=max_len, dtype=\"float32\",\n",
    "                  padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Labels\n",
    "y = df[\"fish_present\"].astype(np.float32).to_numpy()\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y\n",
    ")\n",
    "\n",
    "# Add channel dimension for Conv1D/U-Net\n",
    "X_train = X_train[..., np.newaxis]  # (samples, timesteps, 1)\n",
    "X_val   = X_val[..., np.newaxis]\n",
    "\n",
    "# Ensure labels are numeric\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_val   = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "# Check shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdeb1865-8150-4dd6-a056-158fbb5c1831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4f9903f-1b6a-4762-b666-aee7572fed65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# Simple Conv1D baseline\n",
    "def simple_conv1d(input_length):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv1D(16, 5, activation=\"relu\", input_shape=(input_length, 1)),\n",
    "        layers.MaxPooling1D(2),\n",
    "\n",
    "        layers.Conv1D(32, 5, activation=\"relu\"),\n",
    "        layers.MaxPooling1D(2),\n",
    "\n",
    "        layers.Conv1D(64, 5, activation=\"relu\"),\n",
    "        layers.MaxPooling1D(2),\n",
    "\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "965ee3ee-492c-404c-8ad5-a7e23bcce481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64b188da-71c4-4191-bed4-af82498ae628",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build and train\n",
    "model = simple_conv1d(max_len)\n",
    "\n",
    "# early stops\n",
    "early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=16,\n",
    "    epochs=150,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "888f36ed-928c-407a-9b24-468210e3274b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983b6f9e-c8ad-400d-8988-5429ec8b6c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(dict(zip(model.metrics_names, results)))\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = model.predict(X_val)\n",
    "fpr, tpr, thr = roc_curve(y_val, y_pred_proba)\n",
    "threshold = thr[np.argmax(tpr - fpr)]\n",
    "\n",
    "y_pred = (y_pred_proba > threshold).astype(int).flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466ee3d3-2b04-42a5-a4d3-54481094fcc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training and validation loss curves\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss, label=\"Training Loss\", color=\"tab:blue\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\", color=\"tab:orange\")\n",
    "\n",
    "# Mark the last points\n",
    "plt.scatter(len(train_loss)-1, train_loss[-1], color=\"tab:blue\", s=60, zorder=3)\n",
    "plt.scatter(len(val_loss)-1, val_loss[-1], color=\"tab:orange\", s=60, zorder=3)\n",
    "\n",
    "# Add offset labels with arrows for clarity\n",
    "plt.annotate(f\"{train_loss[-1]:.4f}\",\n",
    "             xy=(len(train_loss)-1, train_loss[-1]),\n",
    "             xytext=(10, 10), textcoords=\"offset points\",\n",
    "             ha=\"left\", color=\"tab:blue\",\n",
    "             arrowprops=dict(arrowstyle=\"->\", color=\"tab:blue\"))\n",
    "\n",
    "plt.annotate(f\"{val_loss[-1]:.4f}\",\n",
    "             xy=(len(val_loss)-1, val_loss[-1]),\n",
    "             xytext=(10, -15), textcoords=\"offset points\",\n",
    "             ha=\"left\", color=\"tab:orange\",\n",
    "             arrowprops=dict(arrowstyle=\"->\", color=\"tab:orange\"))\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c2f851a-c865-4a48-82e9-165c477400b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8c7491-15c3-4258-9ead-9f4968deabf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"No Fish\", \"Fish\"],\n",
    "            yticklabels=[\"No Fish\", \"Fish\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2dea290-1898-4757-9327-df740005352e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Try with Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99d7c924-4c6c-407b-9055-a4d6a950fb2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build and train\n",
    "model1 = simple_conv1d(max_len)\n",
    "\n",
    "# weights\n",
    "class_weights = {0: 1.0, 1: 2.0}   # makes fish mistakes more costly\n",
    "\n",
    "# early stops\n",
    "early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
    "\n",
    "history1 = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9026b308-a6b1-43be-b613-55413eca29b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4ee7665-f9d9-4ae3-92d9-b0db584bf12d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = model1.evaluate(X_val, y_val, verbose=0)\n",
    "print(dict(zip(model1.metrics_names, results)))\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = model1.predict(X_val)\n",
    "fpr, tpr, thr = roc_curve(y_val, y_pred_proba)\n",
    "threshold = thr[np.argmax(tpr - fpr)]\n",
    "\n",
    "y_pred = (y_pred_proba > threshold).astype(int).flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a09430-a1f9-4782-941e-aa4b09507c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training and validation loss curves\n",
    "train_loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss, label=\"Training Loss\", color=\"tab:blue\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\", color=\"tab:orange\")\n",
    "\n",
    "# Mark the last points\n",
    "plt.scatter(len(train_loss)-1, train_loss[-1], color=\"tab:blue\", s=60, zorder=3)\n",
    "plt.scatter(len(val_loss)-1, val_loss[-1], color=\"tab:orange\", s=60, zorder=3)\n",
    "\n",
    "# Add offset labels with arrows for clarity\n",
    "plt.annotate(f\"{train_loss[-1]:.4f}\",\n",
    "             xy=(len(train_loss)-1, train_loss[-1]),\n",
    "             xytext=(10, 10), textcoords=\"offset points\",\n",
    "             ha=\"left\", color=\"tab:blue\",\n",
    "             arrowprops=dict(arrowstyle=\"->\", color=\"tab:blue\"))\n",
    "\n",
    "plt.annotate(f\"{val_loss[-1]:.4f}\",\n",
    "             xy=(len(val_loss)-1, val_loss[-1]),\n",
    "             xytext=(10, -15), textcoords=\"offset points\",\n",
    "             ha=\"left\", color=\"tab:orange\",\n",
    "             arrowprops=dict(arrowstyle=\"->\", color=\"tab:orange\"))\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3bb0dd3-ccec-4bbb-a668-d0fd29c0dc80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05fd924f-30d5-4054-a947-f48572a37e0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"No Fish\", \"Fish\"],\n",
    "            yticklabels=[\"No Fish\", \"Fish\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.1_ Basic1DCNN",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
